{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from config import *\n",
    "import fitz\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity (Chunk ↔ Inclusion): 0.319\n",
      "Cosine Similarity (Chunk ↔ Exclusion): 0.495\n",
      "Cosine Similarity (Chunk ↔ Combined) : 0.4291\n",
      "Contrastive Relevance Score (incl - excl): -0.176\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "    return np.array(response.data[0].embedding)\n",
    "\n",
    "def cos_sim(vec1, vec2):\n",
    "    return cosine_similarity([vec1], [vec2])[0][0]\n",
    "\n",
    "# Define the test texts\n",
    "inclusion_text = \"studies using simulation modeling such as agent-based models, Monte Carlo, and Markov chains.\"\n",
    "exclusion_text = \"studies using only regression analysis or descriptive statistics without simulation.\"\n",
    "combined_text = inclusion_text + \" \\n \" + exclusion_text\n",
    "chunk_text = \"This study uses logistic regression to model heart disease outcomes and not just regression analysis.\"\n",
    "\n",
    "# Get embeddings\n",
    "embedding_inclusion = get_embedding(inclusion_text)\n",
    "embedding_exclusion = get_embedding(exclusion_text)\n",
    "embedding_combined  = get_embedding(combined_text)\n",
    "embedding_chunk     = get_embedding(chunk_text)\n",
    "\n",
    "# Compute similarities\n",
    "sim_incl = cos_sim(embedding_chunk, embedding_inclusion)\n",
    "sim_excl = cos_sim(embedding_chunk, embedding_exclusion)\n",
    "sim_comb = cos_sim(embedding_chunk, embedding_combined)\n",
    "\n",
    "# Print results\n",
    "print(\"Cosine Similarity (Chunk ↔ Inclusion):\", round(sim_incl, 4))\n",
    "print(\"Cosine Similarity (Chunk ↔ Exclusion):\", round(sim_excl, 4))\n",
    "print(\"Cosine Similarity (Chunk ↔ Combined) :\", round(sim_comb, 4))\n",
    "print(\"Contrastive Relevance Score (incl - excl):\", round(sim_incl - sim_excl, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"../data/output\"\n",
    "output_files = os.listdir(OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 corresponds to: PDF_ANNOT_STRIKE_OUT\n"
     ]
    }
   ],
   "source": [
    "# Target value\n",
    "target_value = 11\n",
    "\n",
    "# Reverse lookup\n",
    "for attr in dir(fitz):\n",
    "    if attr.startswith(\"PDF_ANNOT_\"):\n",
    "        if getattr(fitz, attr) == target_value:\n",
    "            print(f\"{target_value} corresponds to: {attr}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:10<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 compliant files:\n",
      "- Burke, Copeland, Sussman, Hayward, Gross, Briceno, Whitney, Giordani, Elkind, Manly, Gottesman, Gaskin, Sidney, Yaffe, Sacco, Heckbert, Hughes, Galecki, Levine_PLOS One_2024_highlighted.pdf\n",
      "- Fouladi, Asadi, Sherer, Madadi__2024_highlighted.pdf\n",
      "- Mihaylova, Wu, Zhou, Williams, Schlackow, Emberson, Reith, Keech, Robson, Parnell, Armitage, Gray, Simes, Baigent_Health Technol. Assess. (winch. Engl.)_2024_highlighted.pdf\n",
      "\n",
      "Total files analyzed: 16\n",
      "Population: 9 files\n",
      "Intervention: 12 files\n",
      "Outcome: 13 files\n",
      "Study approach: 8 files\n",
      "\n",
      "Files meeting all criteria: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "compliant_files = []\n",
    "compliant_dict = {}\n",
    "yes_count = 0\n",
    "no_count = 0\n",
    "total_count = 0\n",
    "\n",
    "for filename in tqdm(output_files):\n",
    "    if not filename.endswith(\"_highlighted.pdf\"):\n",
    "        continue\n",
    "        \n",
    "    pdf_path = os.path.join(OUTPUT_FOLDER, filename)\n",
    "    \n",
    "    # Read the PDF and check for highlights\n",
    "    doc = fitz.open(pdf_path)\n",
    "    found_colors = set()\n",
    "    has_highlights = False\n",
    "    \n",
    "    # Initialize criteria flags for this file\n",
    "    criteria_met = {\n",
    "        'Population': False,\n",
    "        'Intervention': False,\n",
    "        'Outcome': False,\n",
    "        'Study approach': False\n",
    "    }\n",
    "    \n",
    "    # Check each page for highlights\n",
    "    for page in doc:\n",
    "        highlights = page.annots()\n",
    "        \n",
    "        for highlight in highlights:\n",
    "            if highlight.type[0] not in [fitz.PDF_ANNOT_HIGHLIGHT, fitz.PDF_ANNOT_UNDERLINE, fitz.PDF_ANNOT_SQUIGGLY, fitz.PDF_ANNOT_STRIKE_OUT]:\n",
    "                continue\n",
    "                \n",
    "            has_highlights = True\n",
    "            color = highlight.colors[\"stroke\"]\n",
    "            # Convert color tuple to match CRITERIA_COLORS format\n",
    "            color_tuple = (round(color[0], 1), round(color[1], 1), round(color[2], 1))\n",
    "            \n",
    "            # Check if highlight has a comment starting with \"YES\"\n",
    "            comment = highlight.info.get(\"content\", \"\")\n",
    "            if comment.startswith((\"YES\", \"MAYBE\")):\n",
    "                # Add color to set if it's one of the first 4 criteria colors\n",
    "                if color_tuple in list(CRITERIA_COLORS.values())[:4]:\n",
    "                    found_colors.add(color_tuple)\n",
    "                    # Track which criteria are met\n",
    "                    if color_tuple == list(CRITERIA_COLORS.values())[0]:  # Population\n",
    "                        criteria_met['Population'] = True\n",
    "                        yes_count += 1\n",
    "                    elif color_tuple == list(CRITERIA_COLORS.values())[1]:  # Intervention\n",
    "                        criteria_met['Intervention'] = True\n",
    "                        yes_count += 1\n",
    "                    elif color_tuple == list(CRITERIA_COLORS.values())[2]:  # Outcome\n",
    "                        criteria_met['Outcome'] = True\n",
    "                        yes_count += 1\n",
    "                    elif color_tuple == list(CRITERIA_COLORS.values())[3]:  # Study approach\n",
    "                        criteria_met['Study approach'] = True\n",
    "                        yes_count += 1\n",
    "                    else:\n",
    "                        no_count += 1\n",
    "            total_count += 1\n",
    "\n",
    "    # Store criteria for all files with highlights\n",
    "    if has_highlights:\n",
    "        compliant_dict[filename] = criteria_met\n",
    "        \n",
    "        # Check if all 4 colors were found for compliant files list\n",
    "        if len(found_colors) == 4:\n",
    "            compliant_files.append(filename)\n",
    "        \n",
    "    doc.close()\n",
    "\n",
    "# Create DataFrame showing all files and their criteria status\n",
    "df_compliant = pd.DataFrame.from_dict(compliant_dict, orient='index')\n",
    "\n",
    "# Add a column showing if all criteria are met\n",
    "df_compliant['All Criteria Met'] = df_compliant.all(axis=1)\n",
    "df_compliant = df_compliant.reset_index(names='File')\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"Found {len(compliant_files)} compliant files:\")\n",
    "for file in compliant_files:\n",
    "    print(f\"- {file}\")\n",
    "\n",
    "print(f\"\\nTotal files analyzed: {len(df_compliant)}\")\n",
    "\n",
    "for criterion in df_compliant.columns[1:-1]:\n",
    "    count = df_compliant[criterion].sum()\n",
    "    print(f\"{criterion}: {count} files\")\n",
    "\n",
    "print(f\"\\nFiles meeting all criteria: {df_compliant['All Criteria Met'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [12:28<00:00, 41.58s/it]\n"
     ]
    }
   ],
   "source": [
    "color_to_flagname = {\n",
    "    tuple(int(c * 255) for c in list(CRITERIA_COLORS.values())[0]): \"Population\",\n",
    "    tuple(int(c * 255) for c in list(CRITERIA_COLORS.values())[1]): \"Intervention\",\n",
    "    tuple(int(c * 255) for c in list(CRITERIA_COLORS.values())[2]): \"Outcome\",\n",
    "    tuple(int(c * 255) for c in list(CRITERIA_COLORS.values())[3]): \"Study approach\"\n",
    "}\n",
    "\n",
    "def extract_highlighted_text(page, annot):\n",
    "    \"\"\"Extract highlighted text using the highlight's quads.\"\"\"\n",
    "    words = page.get_text(\"words\")  # list of (x0, y0, x1, y1, \"word\", block_no, line_no, word_no)\n",
    "    quads = annot.vertices\n",
    "    sentences = []\n",
    "    if quads:\n",
    "        quad_count = int(len(quads)/4)\n",
    "        for i in range(quad_count):\n",
    "            # Each quad is 4 points, convert to rect\n",
    "            quad = quads[i*4:(i+1)*4]\n",
    "            rect = fitz.Quad(quad).rect\n",
    "            # Find all words within the rect\n",
    "            words_in_rect = [w for w in words if fitz.Rect(w[:4]).intersects(rect)]\n",
    "            text = \" \".join(w[4] for w in words_in_rect)\n",
    "            if text:\n",
    "                sentences.append(text)\n",
    "    return \" \".join(sentences)\n",
    "\n",
    "pdf_comments_dict = {}\n",
    "highlight_buffer = {}\n",
    "\n",
    "for pdf_filename in tqdm(output_files[-1::-1]):\n",
    "    if not pdf_filename.endswith(\"_highlighted.pdf\"):\n",
    "        continue\n",
    "\n",
    "    pdf_path = os.path.join(OUTPUT_FOLDER, pdf_filename)\n",
    "    doc = fitz.open(pdf_path)\n",
    "    file_comments = []\n",
    "\n",
    "    for page in doc:\n",
    "        for annot in page.annots() or []:\n",
    "            if annot.type[0] == 8:  # Highlight\n",
    "                comment_text = annot.info.get(\"content\", \"\")\n",
    "                color_tuple = tuple(int(annot.colors['stroke'][i]*255) for i in range(3)) if annot.colors and 'stroke' in annot.colors else None\n",
    "                flag = None\n",
    "                if color_tuple:\n",
    "                    for ref_tuple, flagname in color_to_flagname.items():\n",
    "                        if color_tuple_close(color_tuple, ref_tuple):\n",
    "                            flag = flagname\n",
    "                            break\n",
    "                if flag is None:\n",
    "                    flag = \"Unknown\"\n",
    "                # Extract highlighted text\n",
    "                chunk_text = extract_highlighted_text(page, annot)\n",
    "                # Buffer by comment to aggregate\n",
    "                if comment_text not in highlight_buffer:\n",
    "                    highlight_buffer[comment_text] = {\n",
    "                        \"flag\": flag,\n",
    "                        \"chunk_text\": chunk_text,\n",
    "                        \"comment_text\": comment_text\n",
    "                    }\n",
    "                else:\n",
    "                    # Concatenate highlighted text if more than one highlight for this comment\n",
    "                    highlight_buffer[comment_text][\"chunk_text\"] += \" \" + chunk_text\n",
    "\n",
    "    # After all annotations processed, save to dict\n",
    "    file_comments = list(highlight_buffer.values())\n",
    "    pdf_comments_dict[pdf_filename] = file_comments\n",
    "    doc.close()\n",
    "    highlight_buffer.clear()  # Clear for next file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>CID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trieu, Huang, Aminde, Cobiac, Coyle, Wanjau, T...</td>\n",
       "      <td>Population</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>WHO recommends lowering population sodium inta...</td>\n",
       "      <td>0 20 40 60 80 –10 10 0 Cumulative health-care ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Comment</td>\n",
       "      <td>YES  \\nScore: 75  \\nThe chunk discusses the ge...</td>\n",
       "      <td>NO  \\nScore: 10  \\nThe chunk primarily present...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title         CID           \\\n",
       "0  Trieu, Huang, Aminde, Cobiac, Coyle, Wanjau, T...  Population    Chunk   \n",
       "1                                                                 Comment   \n",
       "\n",
       "                                                      \\\n",
       "0  WHO recommends lowering population sodium inta...   \n",
       "1  YES  \\nScore: 75  \\nThe chunk discusses the ge...   \n",
       "\n",
       "                                                                ...            \\\n",
       "0  0 20 40 60 80 –10 10 0 Cumulative health-care ...            ...             \n",
       "1  NO  \\nScore: 10  \\nThe chunk primarily present...            ...             \n",
       "\n",
       "             \n",
       "0            \n",
       "1            \n",
       "\n",
       "[2 rows x 80 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_map = {\n",
    "    \"Population\": \"Population\",\n",
    "    \"Intervention\": \"Intervention\",\n",
    "    \"Outcome\": \"Outcome\",\n",
    "    \"Study approach\": \"Study Design\",\n",
    "    \"Study Design\": \"Study Design\"\n",
    "}\n",
    "flags = [\"Population\", \"Intervention\", \"Outcome\", \"Study Design\"]\n",
    "\n",
    "rows = []\n",
    "for filename, highlights in pdf_comments_dict.items():\n",
    "    title = filename.replace(\"_highlighted.pdf\", \"\")\n",
    "    # Group highlights by normalized flag\n",
    "    flag_to_chunks = {flag: [] for flag in flags}\n",
    "    flag_to_comments = {flag: [] for flag in flags}\n",
    "    for h in highlights:\n",
    "        flag = flag_map.get(h[\"flag\"], h[\"flag\"])\n",
    "        if flag in flags:\n",
    "            if h.get(\"chunk_text\"):\n",
    "                flag_to_chunks[flag].append(h[\"chunk_text\"])\n",
    "            if h.get(\"comment_text\"):\n",
    "                flag_to_comments[flag].append(h[\"comment_text\"])\n",
    "    # Build table rows for each flag\n",
    "    for flag in flags:\n",
    "        # Chunk row\n",
    "        chunk_row = [title, flag, \"Chunk\"] + flag_to_chunks[flag]\n",
    "        rows.append(chunk_row)\n",
    "        # Comment row\n",
    "        comment_row = [\"\", \"\", \"Comment\"] + flag_to_comments[flag]\n",
    "        rows.append(comment_row)\n",
    "        title = \"\"  # Only first row per PDF\n",
    "\n",
    "# Find max number of chunks/comments across all flags to pad columns\n",
    "max_cols = max(len(row) for row in rows)\n",
    "for row in rows:\n",
    "    while len(row) < max_cols:\n",
    "        row.append(\"\")\n",
    "\n",
    "columns = [\"Title\", \"CID\", \"\"] + [f\"\" for _ in range(max_cols - 3)]\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "# df.to_excel(\"test.xlsx\", index=False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Population</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Study approach</th>\n",
       "      <th>All Criteria Met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alqahtani, Al-Omar, Alshehri, Abanumay, Alabdu...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Burkart, Brauer, Aravkin, Godwin, Hay, He, Ian...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burke, Copeland, Sussman, Hayward, Gross, Bric...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emmert-Fees, Felea, Staudigel, Ananthapavan, L...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fouladi, Asadi, Sherer, Madadi__2024_highlight...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gibbs, Griffin, Gutacker, Villaseñor, Walker__...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Henkel, Burger, Sletner, Pedersen__2024_highli...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kim, Wang, Lauren, Liu, Marklund, Lee, Micha, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kulhanova et al. - 2018 - The fraction of lung...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mihaylova, Wu, Zhou, Williams, Schlackow, Embe...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pierse, Keogh, O'Neill_BMJ Open_2020_highlight...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rehm, Shield, Roerecke, Gmel_BMC Public Health...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sjule, Vinter, Dueland, Line, Burger, Bjørnelv...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Smit, Perez-Guzman, Mutai, Cassidy, Kibachio, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ten Haaf, de Nijs, Simoni, Alban, Cao, Sun, Yo...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Trieu, Huang, Aminde, Cobiac, Coyle, Wanjau, T...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 File  Population  \\\n",
       "0   Alqahtani, Al-Omar, Alshehri, Abanumay, Alabdu...        True   \n",
       "1   Burkart, Brauer, Aravkin, Godwin, Hay, He, Ian...        True   \n",
       "2   Burke, Copeland, Sussman, Hayward, Gross, Bric...        True   \n",
       "3   Emmert-Fees, Felea, Staudigel, Ananthapavan, L...       False   \n",
       "4   Fouladi, Asadi, Sherer, Madadi__2024_highlight...        True   \n",
       "5   Gibbs, Griffin, Gutacker, Villaseñor, Walker__...        True   \n",
       "6   Henkel, Burger, Sletner, Pedersen__2024_highli...       False   \n",
       "7   Kim, Wang, Lauren, Liu, Marklund, Lee, Micha, ...       False   \n",
       "8   Kulhanova et al. - 2018 - The fraction of lung...        True   \n",
       "9   Mihaylova, Wu, Zhou, Williams, Schlackow, Embe...        True   \n",
       "10  Pierse, Keogh, O'Neill_BMJ Open_2020_highlight...        True   \n",
       "11  Rehm, Shield, Roerecke, Gmel_BMC Public Health...        True   \n",
       "12  Sjule, Vinter, Dueland, Line, Burger, Bjørnelv...       False   \n",
       "13  Smit, Perez-Guzman, Mutai, Cassidy, Kibachio, ...        True   \n",
       "14  ten Haaf, de Nijs, Simoni, Alban, Cao, Sun, Yo...       False   \n",
       "15  Trieu, Huang, Aminde, Cobiac, Coyle, Wanjau, T...        True   \n",
       "\n",
       "    Intervention  Outcome  Study approach  All Criteria Met  \n",
       "0           True     True           False             False  \n",
       "1           True     True            True              True  \n",
       "2           True     True            True              True  \n",
       "3           True    False            True             False  \n",
       "4           True     True            True              True  \n",
       "5          False     True            True             False  \n",
       "6           True     True           False             False  \n",
       "7           True     True           False             False  \n",
       "8           True     True           False             False  \n",
       "9           True     True            True              True  \n",
       "10         False     True            True             False  \n",
       "11          True     True            True              True  \n",
       "12         False    False            True             False  \n",
       "13          True     True            True              True  \n",
       "14          True     True           False             False  \n",
       "15          True    False            True             False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compliant.to_excel(\"../data/excels/compliant_files.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Item Type</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publication Title</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Url</th>\n",
       "      <th>...</th>\n",
       "      <th>Programming Language</th>\n",
       "      <th>Version</th>\n",
       "      <th>System</th>\n",
       "      <th>Code</th>\n",
       "      <th>Code Number</th>\n",
       "      <th>Section</th>\n",
       "      <th>Session</th>\n",
       "      <th>Committee</th>\n",
       "      <th>History</th>\n",
       "      <th>Legislative Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7Z3S4GYD</td>\n",
       "      <td>journalArticle</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Jayasekera, Jinani; Sparano, Joseph A.; O'Neil...</td>\n",
       "      <td>Development and Validation of a Simulation Mod...</td>\n",
       "      <td>Journal of Clinical Oncology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0732-183X</td>\n",
       "      <td>10.1200/JCO.21.00651</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Key       Item Type  Publication Year  \\\n",
       "0  7Z3S4GYD  journalArticle            2021.0   \n",
       "\n",
       "                                              Author  \\\n",
       "0  Jayasekera, Jinani; Sparano, Joseph A.; O'Neil...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Development and Validation of a Simulation Mod...   \n",
       "\n",
       "              Publication Title ISBN       ISSN                   DOI  \\\n",
       "0  Journal of Clinical Oncology  NaN  0732-183X  10.1200/JCO.21.00651   \n",
       "\n",
       "                                                 Url  ...  \\\n",
       "0  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8...  ...   \n",
       "\n",
       "  Programming Language Version System Code Code Number Section  Session  \\\n",
       "0                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "\n",
       "  Committee History  Legislative Body  \n",
       "0       NaN     NaN               NaN  \n",
       "\n",
       "[1 rows x 87 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/excels/Exported Items.csv\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_included = df[df['Manual Tags'].str.contains('obj2_include') & \n",
    "                       df['Manual Tags'].str.contains('test_hand_search|test_medline_search', regex=True)][['Manual Tags', 'File Attachments', 'Title']]\n",
    "df_human_included.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pouri\\\\Zotero\\\\storage\\\\C9VIG9GK\\\\Knudsen et al. - 2016 - Estimation of Benefits, Burden, and Harms of Color.pdf; '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_included.iloc[5]['File Attachments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_human_included[df_human_included['File Attachments'].str.contains('The modelled impact of')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "archive_path = r'C:\\Users\\pouri\\Python\\Lang_Chain\\Projects\\NLP_pipeline_full_text\\data\\papers\\Archive'\n",
    "destination_path = r'C:\\Users\\pouri\\Python\\Lang_Chain\\Projects\\NLP_pipeline_full_text\\data\\papers'\n",
    "\n",
    "# Ensure destination path exists\n",
    "os.makedirs(destination_path, exist_ok=True)\n",
    "\n",
    "# Normalize filenames from the DataFrame column to a set\n",
    "included_files = set(df_human_included['File Attachments'].astype(str).str.split('\\\\').str[-1].str.strip())\n",
    "\n",
    "# Loop through files and copy if in included list\n",
    "for file in os.listdir(archive_path):\n",
    "    if file.strip() in included_files:\n",
    "        shutil.copy2(os.path.join(archive_path, file), os.path.join(destination_path, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>CID</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trieu, Huang, Aminde, Cobiac, Coyle, Wanjau, T...</td>\n",
       "      <td>https://doi.org/10.1016/s2468-2667(24)00221-4</td>\n",
       "      <td>10.1016/s2468-2667(24)00221-4</td>\n",
       "      <td>Population</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>WHO recommends lowering population sodium inta...</td>\n",
       "      <td>0 20 40 60 80 –10 10 0 Cumulative health-care ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comment</td>\n",
       "      <td>YES  \\nScore: 75  \\nThe chunk discusses the ge...</td>\n",
       "      <td>NO  \\nScore: 10  \\nThe chunk primarily present...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Trieu, Huang, Aminde, Cobiac, Coyle, Wanjau, T...   \n",
       "1                                                NaN   \n",
       "\n",
       "                                             DOI  \\\n",
       "0  https://doi.org/10.1016/s2468-2667(24)00221-4   \n",
       "1                                            NaN   \n",
       "\n",
       "                      Unnamed: 2         CID Unnamed: 4  \\\n",
       "0  10.1016/s2468-2667(24)00221-4  Population      Chunk   \n",
       "1                            NaN         NaN    Comment   \n",
       "\n",
       "                                                   1  \\\n",
       "0  WHO recommends lowering population sodium inta...   \n",
       "1  YES  \\nScore: 75  \\nThe chunk discusses the ge...   \n",
       "\n",
       "                                                   2    3    4    5  ...   71  \\\n",
       "0  0 20 40 60 80 –10 10 0 Cumulative health-care ...  NaN  NaN  NaN  ...  NaN   \n",
       "1  NO  \\nScore: 10  \\nThe chunk primarily present...  NaN  NaN  NaN  ...  NaN   \n",
       "\n",
       "    72   73   74   75   76   77  78  79  80  \n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN NaN NaN NaN  \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN NaN NaN NaN  \n",
       "\n",
       "[2 rows x 85 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reference = pd.read_excel(\"../data/excels/full_text_fuzzy_eval.xlsx\", sheet_name=\"Reference\")\n",
    "df_reference.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pairs = []\n",
    "for i in range(0, len(df_reference), 2):\n",
    "    pair = []\n",
    "    \n",
    "    row1 = df_reference.iloc[i, 5:].dropna().tolist()\n",
    "    pair.append(row1)\n",
    "    \n",
    "    if i + 1 < len(df_reference):\n",
    "        row2 = df_reference.iloc[i + 1, 5:].dropna().tolist()\n",
    "        pair.append(row2)\n",
    "    \n",
    "    grouped_pairs.append(pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUSION_CRITERIA = [\n",
    "    \"\"\"\n",
    "    Population - Populations at risk of developing an NCD (Non-Communicable Diseases)\n",
    "    Studies of real or generalizable human populations at risk of developing NCDs. These may be defined by geographic, demographic, or social characteristics (e.g., national population, region, age group).\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Intervention, exposure, or scenario (includes comparator) \n",
    "    Studies evaluating health impacts of exposures, interventions, or policies on NCD outcomes through simulation of hypothetical scenarios. Includes burden-of-disease and comparative risk assessment studies.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Outcome - Selected non-communicable diseases (NCDs - Non-Communicable Diseases) or NCD risk factors \n",
    "    Studies reporting on outcomes related to major NCDs (e.g., cardiovascular disease, cancer, diabetes, chronic respiratory diseases, mental health, neurological disorders, injury, or musculoskeletal conditions) or their risk factors.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Study approach - Computational simulation modelling \n",
    "    Studies that use computational simulation modeling (e.g., system dynamics, agent-based models, microsimulation, Markov models, or attributable risk models) as the primary method of analysis.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "EXCLUSION_CRITERIA = [\n",
    "    \"\"\"\n",
    "    Studies focusing exclusively on individuals already diagnosed with NCDs or using highly specific clinical cohorts without generalizability.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Studies that focus exclusively on tertiary prevention or do not simulate hypothetical scenarios (e.g., purely observational studies).\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Studies that are primarily health economic evaluations (e.g., cost-effectiveness analyses) or those focusing only on non-NCD outcomes.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Studies using regression, observational methods, trend forecasts, or risk prediction models that do not simulate interventions.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from collections import defaultdict\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [13:17<00:00, 11.72s/it]\n"
     ]
    }
   ],
   "source": [
    "responses = defaultdict(list)\n",
    "for i, pair in enumerate(tqdm(grouped_pairs)):\n",
    "    for row1_text, row2_text in zip(pair[0], pair[1]):\n",
    "        prompt = f\"\"\"\n",
    "            You are a systematic review assistant.\n",
    "            Here are the inclusion criteria:\n",
    "            {INCLUSION_CRITERIA[i%4]}\n",
    "\n",
    "            Here are the exclusion criteria:\n",
    "            {EXCLUSION_CRITERIA[i%4]}\n",
    "\n",
    "            First row (study info): {row1_text}\n",
    "            Second row (provided decision): {row2_text}\n",
    "\n",
    "            Task:\n",
    "            1. State if you agree with the second row's decision (YES=INCLUDE, NO=EXCLUDE).\n",
    "            2. Give a short reason.\n",
    "            \n",
    "            Answer in this format:\n",
    "            Agrees: ...\n",
    "            Reason: ...\n",
    "        \"\"\"\n",
    "\n",
    "        response = llm.invoke(prompt)\n",
    "        responses[i+1].append(response.content)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
