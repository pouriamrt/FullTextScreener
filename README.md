# üß† NLP Pipeline for Full-Text Screening Using LLMs and Embeddings

This repository implements a comprehensive pipeline to **automate the full-text screening** of scientific literature (PDF format). It integrates **OpenAI embeddings**, **LLM-based validation (GPT-4.1-mini)**, optional **BioBERT fine-tuning**, and **contrastive inclusion/exclusion scoring**. The pipeline outputs **annotated PDFs** with highlights, tooltips, and **compliance reports** for systematic review support.

---

## üìÇ Repository Structure

```
.
‚îú‚îÄ‚îÄ main.py                       # Entry point for running the full pipeline
‚îú‚îÄ‚îÄ config.py                     # Inclusion/exclusion criteria, thresholds, colors, API keys
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ biobert_trainer.py        # Optional: fine-tune BioBERT with labeled data
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ check_chunk_llm.py        # Batch/single LLM verification of candidate chunks
‚îÇ   ‚îú‚îÄ‚îÄ cost_tracker.py           # Tracks OpenAI API usage and cost with plots
‚îÇ   ‚îú‚îÄ‚îÄ embedding.py              # Embedding functions with caching
‚îÇ   ‚îú‚îÄ‚îÄ get_pdfs_from_zotero.py   # Utility to fetch papers from Zotero libraries
‚îÇ   ‚îú‚îÄ‚îÄ pdf_highlighter.py        # Annotates PDFs with highlights and comments
‚îÇ   ‚îú‚îÄ‚îÄ pdf_parser.py             # Extracts sentence-based text chunks from PDFs
‚îÇ   ‚îú‚îÄ‚îÄ plotting.py               # Helper for compliance and result visualizations
‚îÇ   ‚îî‚îÄ‚îÄ similarity.py             # Cosine similarity + contrastive scoring (incl. exclusion)
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ compliant_files.ipynb     # Example analysis: compliance stats and evaluation
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ papers/                   # Input: drop PDFs here (or sync from Zotero)
‚îÇ   ‚îú‚îÄ‚îÄ output/                   # Output: annotated PDFs and reports
‚îÇ   ‚îî‚îÄ‚îÄ excels/                   # Tabular compliance summaries
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ LICENSE
‚îî‚îÄ‚îÄ .gitignore
```

---

## üß† What This Pipeline Does

### Problem
Systematic review full-text screening is manual, slow, and subjective. This project automates semantic triage of PDFs using embeddings and LLM reasoning.

### Solution Workflow
1. üìÑ Parse PDFs into overlapping sentence chunks.
2. üî¢ Embed each chunk with OpenAI `text-embedding-3-large`.
3. ‚öñÔ∏è Score similarity against **both inclusion and exclusion criteria**.
4. ‚úÖ Verify borderline/high-scoring chunks with GPT-4.1-mini (YES/NO/MAYBE + explanation).
5. üñçÔ∏è Annotate PDFs with criterion-colored highlights and reasoning tooltips.
6. üìä Generate compliance reports (Excel, plots, token/cost tracking).

---

## üèóÔ∏è Pipeline Architecture

### Overview
1. PDFs ‚Üí `data/papers/`
2. Sentence-based chunking (sliding windows)
3. Embedding generation + caching
4. Contrastive similarity scoring (inclusion vs. exclusion)
5. LLM batch verification (`check_chunk_llm.py`)
6. PDF annotation (`pdf_highlighter.py`)
7. Compliance stats & plots (`plotting.py`)
8. Annotated outputs ‚Üí `data/output/`

### Diagram

```mermaid
flowchart TD
    A["Input PDFs"] --> B["Sentence-based chunking"]
    B --> C["Embedding generation"]
    C --> D["Similarity scoring vs inclusion and exclusion"]
    D -- "Above threshold" --> E["LLM verification - GPT-4_1 mini"]
    E --> F["Validated chunks and reasoning"]
    F --> G["Annotate PDF highlights and comments"]
    G --> H["Reports, plots, annotated PDFs"]


---

## üîç Inclusion & Exclusion Criteria

Defined in `config.py`:

- **Inclusion Criteria**: e.g., Population, Intervention, Outcome, Study Design.
- **Exclusion Criteria**: e.g., overly clinical cohorts, observational-only studies, non-NCD focus, regression-only methods.
- Each criterion has:
  - Descriptive text
  - Label
  - Highlight color

---

## üß™ How Matching Works

1. **Chunking**: `pdf_parser.py` uses PyMuPDF to create overlapping sentence windows.
2. **Embedding**: Chunks and criteria embedded via OpenAI API (`embedding.py`).
3. **Contrastive Scoring**: `similarity.py` compares chunk embeddings to **both inclusion and exclusion** vectors.
4. **LLM Verification**:  
   - `check_chunk_llm.py` uses GPT-4.1-mini (via LangChain).  
   - Assigns **YES/NO/MAYBE** with score + justification.  
   - Supports batch mode with concurrency control.
5. **Annotation**: `pdf_highlighter.py` highlights matched text in criterion colors and adds LLM explanations as tooltips.
6. **Reporting**: `plotting.py` + notebooks produce Excel compliance tables, summary plots, and cost tracking (`cost_tracker.py`).

---

## ‚öôÔ∏è Configuration

Adjust in `config.py`:
- `INCLUSION_CRITERIA` / `EXCLUSION_CRITERIA`
- `SIMILARITY_THRESHOLD`
- `SENTENCES_PER_CHUNK`
- `CRITERIA_COLORS`
- `LLM_MODEL`, `EMBED_MODEL`
- Cost plot output folder

---

## üöÄ Getting Started

### Install
```bash
pip install -r requirements.txt
```

### API Key
Create `.env`:
```
OPENAI_API_KEY=your-key-here
```

### Run
```bash
python main.py
```

### Review Outputs
- Annotated PDFs ‚Üí `data/output/`
- Compliance tables ‚Üí `data/excels/`
- Cost plots ‚Üí `plots/`

---

## üî¨ Optional: BioBERT Training

Fine-tune BioBERT with labeled inclusion/exclusion data:

```python
from models.biobert_trainer import train_biobert
train_biobert([
    {"text": "NCD simulation model using burden-of-disease", "label": 1},
    {"text": "Descriptive regression only", "label": 0},
])
```

---

## üìä Additional Features
- Zotero integration (`get_pdfs_from_zotero.py`) for syncing papers.
- API cost tracking (`cost_tracker.py`) with usage plots.
- Compliance exploration notebooks (`notebooks/compliant_files.ipynb`).

---

## üí° Use Cases
- Systematic reviews
- Automated triage of scientific PDFs
- Transparent inclusion/exclusion filtering
- NLP pipelines for health modeling and evidence synthesis

---

## üìú License
MIT License.

---

## üôè Acknowledgments
- [OpenAI](https://openai.com/)  
- [LangChain](https://www.langchain.com/)  
- [HuggingFace](https://huggingface.co/)  
- [PyMuPDF](https://pymupdf.readthedocs.io/)  
