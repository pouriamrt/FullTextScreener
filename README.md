# üß† NLP Pipeline for Full-Text Screening Using LLMs and Embeddings

This repository implements a comprehensive pipeline to **automate the full-text screening** of scientific literature, particularly research papers in PDF format. It combines **OpenAI embeddings**, **LLM-based validation (GPT-4.1-mini)**, and optional **BioBERT fine-tuning** to assess whether text segments satisfy **user-defined inclusion criteria**. The output includes **annotated PDFs** with highlighted sections and justifications for each inclusion.

---

## üìÇ Repository Structure

```
.
‚îú‚îÄ‚îÄ main.py                       # Entry point for the entire pipeline
‚îú‚îÄ‚îÄ config.py                     # Inclusion criteria, colors, thresholds, API keys
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ biobert_trainer.py        # Optional: Fine-tune BioBERT on labeled data
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ check_chunk_llm.py        # LLM-based verification of semantic matches
‚îÇ   ‚îú‚îÄ‚îÄ embedding.py              # OpenAI embedding generator with caching
‚îÇ   ‚îú‚îÄ‚îÄ pdf_highlighter.py        # Applies highlights and tooltips to matched PDF text
‚îÇ   ‚îú‚îÄ‚îÄ pdf_parser.py             # Extracts sentence-based text chunks from PDFs
‚îÇ   ‚îî‚îÄ‚îÄ similarity.py             # Computes cosine similarity and filters matches
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ papers/                   # Input folder: drop PDFs to be screened here
‚îÇ   ‚îî‚îÄ‚îÄ output/                   # Output folder: highlighted and annotated PDFs
‚îî‚îÄ‚îÄ .gitignore
```

---

## üß† What This Pipeline Does

### Problem
In systematic reviews or screening tasks, full-text PDF review is labor-intensive and subjective. This project automates the screening pipeline with semantic and logical checks using modern NLP tools.

### Solution Workflow
1. üìÑ Input PDFs are chunked into overlapping sentences.
2. üî¢ Each chunk is embedded using OpenAI‚Äôs `text-embedding-3-large`.
3. üß† The chunk is semantically compared to pre-embedded inclusion criteria.
4. ‚úÖ Chunks with high similarity are verified using GPT-4.1-mini for human-like judgment.
5. üñçÔ∏è Validated chunks are annotated in the PDF with highlights and reasoning tooltips.

---

## üèóÔ∏è Pipeline Architecture

### üß≠ Overview

1. üìÑ **Input PDFs** placed in `data/papers/`
2. üß© **Sentence-Based Chunking** (sliding windows with overlap)
3. üî¢ **Embedding Generation** using `text-embedding-3-large`
4. üìê **Cosine Similarity Scoring** vs. inclusion criteria
5. ü§ñ **LLM Verification** using `GPT-4.1-mini`
6. üß† **Store Validated Chunks** with LLM-generated reasoning
7. üñçÔ∏è **Highlight Matched Text** in original PDF
8. üìÇ **Save Annotated PDFs** to `data/output/`

### üó∫Ô∏è Mermaid Diagram

```mermaid
flowchart TD
    A[Input PDFs (data/papers)] --> B[Sentence-Based Chunking]
    B --> C[Embedding Generation (text-embedding-3-large)]
    C --> D[Cosine Similarity Scoring vs. Inclusion Criteria]
    D -->|Above Threshold| E[LLM Verification (GPT-4.1-mini)]
    E --> F[Store Validated Chunks with Reasoning]
    F --> G[Highlight Matches in PDF]
    G --> H[Output PDFs (data/output)]
```

---

## üîç Inclusion Criteria Explained

All inclusion criteria are defined in `config.py`. Each one contains:
- A **descriptive paragraph** used for semantic matching.
- A **label** (e.g., "Population", "Intervention").
- A **color code** used for highlighting.

These criteria are first embedded using OpenAI and then used to compare against paper chunks.

---

## üß™ How Matching Works (Deep Dive)

1. **Chunking**:
   - PDFs are read page-by-page using `PyMuPDF`.
   - Each page is split into sliding windows of 3‚Äì4 sentences with overlaps to ensure context continuity.
   - Each chunk is associated with its originating page number.

2. **Embedding**:
   - Both inclusion criteria and chunks are embedded using `text-embedding-3-large`.
   - Each chunk becomes a dense vector in semantic space.

3. **Similarity Scoring**:
   - Cosine similarity is calculated between each chunk vector and every criterion vector.
   - The chunk is assigned the criterion with the highest similarity.
   - Only chunks with similarity above a threshold (e.g., 0.5) are retained.

4. **LLM Verification**:
   - GPT-4.1-mini is queried via LangChain with:
     - The chunk‚Äôs text
     - The matched criterion label
     - The full inclusion criterion description
   - The model answers:
     - YES or NO
     - An explanation (1‚Äì2 sentences)

5. **Annotation**:
   - Matched and verified chunks are saved with:
     - Criterion label and ID
     - Page number
     - GPT explanation
   - The original PDF is re-opened, and the matched text is highlighted.
   - Hover annotations in the PDF show the model‚Äôs reasoning.

6. **Output**:
   - Annotated PDFs are stored in `data/output/` for human review and traceability.

---

## ‚öôÔ∏è Configuration

You can modify the following in `config.py`:
- `INCLUSION_CRITERIA`: Paragraph descriptions of each criterion.
- `SIMILARITY_THRESHOLD`: Filter threshold for cosine similarity.
- `SENTENCES_PER_CHUNK`: Controls chunk granularity.
- `CRITERIA_COLORS`: Colors for each criterion‚Äôs highlight.
- `LLM_MODEL`, `OPENAI_MODEL`: Choose models to use.

---

## üöÄ Getting Started

### Step 1: Install Requirements

```bash
pip install -r requirements.txt
```

### Step 2: Set Up API Key

Create a `.env` file with:

```
OPENAI_API_KEY=your-key-here
```

### Step 3: Add PDFs

Drop PDFs into the input folder:

```
data/papers/
```

### Step 4: Run the Pipeline

```bash
python main.py
```

### Step 5: Review Annotated PDFs

Output files with highlights and LLM comments will be saved in:

```
data/output/
```

---

## üî¨ Optional: Train BioBERT on Labeled Data

If you have labeled inclusion/exclusion data:

```python
from models.biobert_trainer import train_biobert

train_biobert([
    {"text": "This is an NCD simulation model using burden-of-disease.", "label": 3},
    ...
])
```

This uses HuggingFace‚Äôs Trainer API for supervised fine-tuning.

---

## üí° Use Cases

- Systematic review support
- Automated inclusion/exclusion filtering
- Transparent evidence triage in health modeling
- Semantic filtering in scientific NLP pipelines

---

## üìú License

This project is released under the MIT License.

---

## üôè Acknowledgments

- [OpenAI](https://openai.com/)
- [LangChain](https://www.langchain.com/)
- [HuggingFace](https://huggingface.co/)
- [PyMuPDF](https://pymupdf.readthedocs.io/)